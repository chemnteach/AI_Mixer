---
session: onboarding
date: 2026-02-16
project: AI_Mixer
type: comprehensive_overview

# ============================================================================
# PROJECT OVERVIEW
# ============================================================================

project_name: The Mixer + Crossfade Club
tagline: "AI-powered audio mashup pipeline with automated video generation"
status: Production Ready (Audio) / Asset Acquisition Phase (Video)

tech_stack:
  primary_language: Python 3.9+
  orchestration:
    - LangGraph (agent state machine)
    - langchain (LLM integration)
  audio_processing:
    - librosa (analysis)
    - openai-whisper (transcription)
    - demucs (stem separation)
    - pyrubberband (time-stretching)
    - pydub (mixing/export)
  vector_db: ChromaDB 0.4.22 (pinned)
  llm_providers:
    - Anthropic Claude 3.5 Sonnet (primary)
    - OpenAI GPT-4 Turbo (fallback)
  video_pipeline:
    - Blender 3.6+ (3D rendering)
    - FFmpeg (encoding)
  ui_frameworks:
    - Streamlit (web interface)
    - Click + Rich (CLI)
  testing: pytest + pytest-cov

system_dependencies:
  required:
    - Python 3.9+
    - ffmpeg
  recommended:
    - libsndfile
    - Blender 3.6+ (for video generation)
  optional:
    - CUDA 11.8+ (GPU acceleration for Demucs/Whisper)

# ============================================================================
# WHAT EXISTS AND WORKS (PRODUCTION READY)
# ============================================================================

completed_features:

  # PHASE 0-7: AUDIO PIPELINE - COMPLETE ✅
  audio_mashup_system:
    status: production_ready
    completion_date: 2026-01-19
    test_coverage: 170+ unit tests

    components:

      foundation:
        - Directory structure and configuration system
        - ConfigManager with dot-notation access (mixer/config.py)
        - Structured logging with rotation
        - Production-ready CLI (mixer/cli.py - 645 lines)
        - Entry point (mixer/__main__.py)

      memory_system:
        status: complete
        files:
          - mixer/memory/client.py (ChromaDB singleton)
          - mixer/memory/schema.py (ID sanitization, validation)
          - mixer/memory/queries.py (harmonic/semantic/hybrid matching)
        features:
          - Persistent ChromaDB storage (./chroma_db/)
          - Song ID sanitization (artist_title format)
          - Three query modes (harmonic, semantic, hybrid)
          - Camelot wheel key compatibility
          - Metadata validation (BPM, key, energy, irony)
        tests: 47 unit tests (98% coverage)

      ingestion_agent:
        status: complete
        file: mixer/agents/ingestion.py
        features:
          - Local file support (WAV, MP3, FLAC)
          - YouTube ingestion (yt-dlp)
          - Batch folder ingestion (CD rips)
          - YouTube playlist extraction
          - Cache checking and deduplication
          - Format conversion via ffmpeg
          - Retry logic with exponential backoff
        tests: 22 unit tests (95% coverage)

      analyst_agent:
        status: complete
        files:
          - mixer/agents/analyst.py (orchestrator)
          - mixer/audio/analysis.py (signal processing)
          - mixer/llm/semantic.py (LLM analysis)
        features:
          - Section-level metadata extraction
          - Section detection (agglomerative clustering)
          - Energy analysis per section (RMS, spectral centroid)
          - Vocal analysis (density, intensity)
          - Semantic analysis via LLM (mood, themes, lyrical function)
          - Emotional arc generation
          - Word-level timing storage (for future features)
        tests: 10 unit tests (92% coverage)

      engineer_agent:
        status: complete
        files:
          - mixer/agents/engineer.py (676 lines, all 8 mashup types)
          - mixer/audio/processing.py (stem separation, pitch-shifting)
        features:
          - 8 mashup types implemented
          - Quality presets (draft/high/broadcast)
          - Automatic BPM alignment
          - Stem separation (Demucs)
          - Time-stretching (pyrubberband)
          - Pitch-shifting (librosa)
          - First downbeat alignment
        mashup_types:
          simple:
            - classic (Vocal A + Instrumental B)
            - stem_swap (Mix stems from 3+ songs)
          energy_based:
            - energy_matched (Align by energy curves)
            - adaptive_harmony (Auto-fix key clashes via pitch-shift)
          semantic:
            - theme_fusion (Filter sections by lyrical themes)
            - semantic_aligned (Question→answer, narrative→reflection pairing)
          interactive:
            - role_aware (Vocals shift between lead/harmony/call/response)
            - conversational (Songs talk to each other with silence gaps)
        tests: 48 unit tests (93% coverage)

      curator_agent:
        status: complete
        file: mixer/agents/curator.py (190 lines)
        features:
          - Song pairing and compatibility scoring
          - Weighted scoring (BPM 35%, key 30%, energy 20%, genre 15%)
          - Mashup type recommendation (decision tree)
          - Batch pair discovery
          - Harmonic/semantic/hybrid matching integration
        functions:
          - find_match() (single best match)
          - calculate_compatibility_score() (weighted)
          - recommend_mashup_type() (heuristic decision tree)
          - find_all_pairs() (batch recommendations)
        tests: 19 unit tests (94% coverage)

      workflow_orchestration:
        status: complete
        files:
          - mixer/workflow/state.py (state definitions)
          - mixer/workflow/nodes.py (agent wrapper nodes)
          - mixer/workflow/graph.py (LangGraph workflow)
        features:
          - Multi-agent state machine
          - Conditional routing (auto-match vs user-provided song B)
          - Human-in-the-loop approval points
          - Error handling with retry (max 3 attempts)
          - Progress message streaming
          - Auto-selection fallback
        workflow_nodes:
          - ingest_song_a, analyze_song_a
          - ingest_song_b, analyze_song_b
          - find_matches, await_user_selection
          - recommend_mashup_type, await_mashup_approval
          - create_mashup, error_handler
        tests: 25 unit tests (68-73% coverage)

      cli_interface:
        status: production_ready
        file: mixer/cli.py (645 lines)
        features:
          - Rich formatting (progress bars, tables, panels)
          - Auto mode (one-command mashup)
          - Interactive mode (guided workflow with prompts)
          - All 8 mashup types supported
          - Library management (list, search, stats)
        commands:
          - ingest (file/youtube/folder/playlist)
          - analyze (single/batch)
          - match (harmonic/semantic/hybrid)
          - mashup (all 8 types)
          - library (list/search/stats)
          - auto (fully automated)
          - interactive (guided mode)

      web_ui:
        status: complete
        file: mixer_ui.py (1066 lines)
        features:
          - Streamlit interface with 4 tabs
          - Create Mashup (auto/manual modes)
          - Library Management (browse/ingest/search/stats)
          - Generate Video (Crossfade Club - disabled pending assets)
          - Settings viewer
          - File upload and audio playback
          - Visual metadata display
          - Charts and statistics
        documentation: UI_GUIDE.md (comprehensive usage guide)

  # CROSSFADE CLUB: VIDEO PIPELINE - CODE COMPLETE ✅ (ASSETS NEEDED)
  video_generation_system:
    status: code_complete_awaiting_assets
    completion_date: 2026-01-20
    test_coverage: 67 tests (100% pass rate)
    blocker: Requires 8 Blender .blend files (1/8 complete)

    components:

      director_agent:
        status: complete
        location: director/
        files:
          - timeline.py (visual timeline generation)
          - events.py (audio moment detection)
          - camera.py (energy-driven camera paths)
          - themes.py (theme config loader)
          - safety.py (event-safe validation)
        features:
          - Generates timeline.json from audio metadata
          - Event detection (drops, section changes, retention nudges)
          - Camera path generation (zoom, pan, nudge)
          - 4 themes (sponsor_neon, award_elegant, mashup_chaos, chill_lofi)
          - Event-safe mode for client deliverables
          - Usage manifest generation (legal compliance)
        tests: 23 unit tests

      studio_module:
        status: complete
        location: studio/
        files:
          - renderer.py (Blender subprocess orchestration)
          - asset_loader.py (validates .blend assets)
          - blender_scripts/animate.py (runs inside Blender)
        features:
          - Blender subprocess integration
          - Asset validation (8 required .blend files)
          - Placeholder mode for testing without assets
          - Headless rendering support
          - Comprehensive asset specifications
        tests: 16 unit tests
        documentation: studio/assets/README.md (asset specs)

      encoder_module:
        status: complete
        location: encoder/
        files:
          - platform.py (platform-specific variants)
          - captions.py (burn-in caption system)
          - thumbnail.py (smart thumbnail extraction)
        features:
          - Platform variants (TikTok/Reels/Shorts 9:16, YouTube 16:9)
          - H.264 video + AAC audio encoding
          - Caption burn-in (FFmpeg subtitle filter)
          - WebVTT caption generation
          - Platform-specific bitrates
          - Thumbnail extraction
        output_formats:
          tiktok: 1080x1920, 5M bitrate, burned captions
          reels: 1080x1920, 5M bitrate, burned captions
          shorts: 1080x1920, 5M bitrate, burned captions
          youtube: 1920x1080, 8M bitrate, soft subtitles
          thumbnail: 1280x720 JPEG
        tests: 20 unit tests

      batch_runner:
        status: complete
        location: batch/
        files:
          - runner.py (end-to-end orchestration)
        features:
          - One-command pipeline execution
          - Director → Studio → Encoder orchestration
          - Stage timing and performance metrics
          - Skip-studio mode for testing
          - Error handling with stage-specific errors
        entry_point: run_batch.py
        tests: 4 integration tests
        documentation: batch/README.md (pipeline guide)

# ============================================================================
# IN PROGRESS / PARTIALLY COMPLETE
# ============================================================================

in_progress:

  blender_asset_acquisition:
    status: in_progress (1 of 8 assets complete)
    current_phase: Asset acquisition
    last_updated: 2026-01-27

    completed_assets:
      - name: avatar_base.blend
        path: studio/assets/avatar_base.blend
        status: complete (Session 13)
        size: 1.3 MB
        source: Sketchfab (free download)
        notes: DJ character with working rig from Auto-Rig Pro

    remaining_assets:
      animations_from_mixamo:
        priority: high
        count: 6
        source: mixamo.com (free Adobe account)
        files:
          - idle_bob.blend (idle animation with weight shift)
          - deck_scratch_L.blend (left turntable scratch)
          - deck_scratch_R.blend (right turntable scratch)
          - crossfader_hit.blend (crossfader slide gesture)
          - drop_reaction.blend (excited/victory gesture)
          - spotlight_present.blend (pointing/greeting motion)
        effort: Low (just download FBX, import to Blender, save)

      dj_booth_environment:
        priority: medium
        name: studio_default.blend
        source: Sketchfab/BlendSwap or manual modeling
        requirements:
          - DJ booth with left/right decks
          - Crossfader at center
          - Camera positioned for medium shot
          - 3-point lighting rig
        effort: Medium (find free asset or model simple version)

    next_steps:
      - Download 5-6 animations from Mixamo
      - Import FBX files into Blender
      - Save each as separate .blend file in actions/ folder
      - Find or create DJ booth environment
      - Run asset validation: `python -c "from studio.asset_loader import validate_assets; print(validate_assets())"`

    research_completed:
      - Multi-LLM asset research (OpenAI, Claude, Gemini, Perplexity)
      - See docs/research/blender-assets/synthesis.md
      - Decided on ultra-budget path ($0 - found free alternatives)

# ============================================================================
# MISSING / NOT YET IMPLEMENTED
# ============================================================================

missing_features:

  audio_pipeline:
    # Audio pipeline is COMPLETE - no missing features
    notes: All 7 phases delivered and tested

  video_pipeline:
    core_implementation:
      status: complete
      notes: All code exists and passes tests

    missing_components:
      blender_assets:
        required_count: 8
        completed_count: 1
        remaining_count: 7
        blocker: true
        impact: Video generation disabled in UI until assets ready
        estimated_effort: 2-4 hours (mostly downloading and importing)

    ui_integration:
      status: implemented but disabled
      location: mixer_ui.py (Generate Video tab)
      notes: Code exists, disabled via st.info() pending assets
      enable_when: All 8 .blend files present in studio/assets/

  future_enhancements:

    crossfade_club_v1_1:
      - Parallel platform encoding (~50% speedup)
      - Asset upload interface in UI
      - Video preview player
      - Real-time rendering preview

    crossfade_club_v2_0:
      - Wardrobe system (outfit swapping per song/season)
      - Props system (sunglasses, headphones, glow sticks)
      - Multiple avatar characters
      - Additional studio environments
      - Custom animation action library

    mixer_enhancements:
      - Real-time preview of mashups before full render
      - Batch mashup generation (multiple pairs at once)
      - Export project files (save workflow state)
      - Cloud deployment for web access
      - Streaming integration (Spotify, SoundCloud)

# ============================================================================
# TESTING STATUS
# ============================================================================

testing:
  total_tests: 237+
  pass_rate: 100%

  breakdown:
    mixer_core:
      total: 170+
      coverage: 85-98%
      tests:
        - Phase 1 (Memory): 47 tests, 98% coverage
        - Phase 2 (Ingestion): 22 tests, 95% coverage
        - Phase 3A (Analyst): 10 tests, 92% coverage
        - Phase 3B-3E (Engineer): 48 tests, 93% coverage
        - Phase 4 (Curator): 19 tests, 94% coverage
        - Phase 5 (Workflow): 25 tests, 68-73% coverage
        - Integration: E2E workflow, CLI integration

    crossfade_club:
      total: 67
      pass_rate: 100%
      tests:
        - Director: 23 tests
        - Studio: 16 tests
        - Encoder: 20 tests
        - Batch: 4 tests
        - Integration: 4 tests

  skipped_tests:
    - Integration tests requiring real audio files (network access)
    - Performance benchmarks (manual run only)
    - Full workflow tests (require LLM API keys)

  test_commands:
    unit_all: pytest tests/ -v --cov=mixer --cov=director --cov=studio --cov=encoder --cov=batch
    mixer_only: pytest tests/unit/ -v
    crossfade_only: pytest tests/director/ tests/studio/ tests/encoder/ tests/batch/ -v
    single_module: pytest tests/unit/test_memory.py -v
    with_coverage: pytest tests/ -v --cov=mixer --cov-report=html

# ============================================================================
# ARCHITECTURE & KEY DECISIONS
# ============================================================================

architecture:

  design_pattern: Agent-based pipeline with state machine orchestration

  data_flow:
    audio_pipeline:
      - User uploads audio (local file or YouTube URL)
      - Ingestion Agent downloads/caches audio
      - Analyst Agent extracts metadata (BPM, key, sections, lyrics, mood)
      - Metadata stored in ChromaDB with embeddings
      - Curator Agent finds compatible matches
      - Engineer Agent creates mashup (8 types available)
      - Output saved to ./mashups/

    video_pipeline:
      - Mixer audio mashup (or single song)
      - Director Agent generates timeline.json
      - Studio Module renders 3D animation (Blender)
      - Encoder Module creates platform variants (FFmpeg)
      - Output saved to platform-specific folders

  memory_system:
    database: ChromaDB (local persistent)
    collection: tiki_library
    id_format: "{artist}_{title}" (sanitized)
    document_format: "{transcript}\n\n[MOOD]: {mood_summary}"
    embeddings: sentence-transformers/all-MiniLM-L6-v2 (384-dim)

    query_modes:
      harmonic: BPM tolerance (±5%) + Camelot wheel key compatibility
      semantic: Mood, genre, vibe similarity via embeddings
      hybrid: 60% harmonic + 40% semantic (RRF - Reciprocal Rank Fusion)

  key_decisions:
    - ChromaDB 0.4.22 pinned for stability
    - Hybrid matching recommended (60/40 harmonic/semantic)
    - Section-level metadata foundation for advanced mashups
    - LangGraph for multi-agent orchestration
    - Streamlit for web UI (pure Python, fast development)
    - Blender for 3D rendering (industry standard, Python API)
    - Platform-aware batch encoding (TikTok/Reels/Shorts/YouTube)
    - Event-safe guardrails for client deliverables
    - Asset template library separate from code (licensing)

# ============================================================================
# KNOWN ISSUES & CONSTRAINTS
# ============================================================================

known_issues:

  blockers:
    - name: Blender assets required
      impact: Video generation disabled in UI
      remaining_count: 7 of 8 assets
      estimated_fix_time: 2-4 hours
      mitigation: Studio module has placeholder mode for testing

  constraints:
    - YouTube TOS: yt-dlp usage technically violates TOS (warn users)
    - Large install: PyTorch dependencies ~5GB total
    - GPU memory: Demucs peak usage ~8GB VRAM (fallback to CPU available)
    - Cache management: Need LRU eviction if library exceeds 50GB
    - Video rendering time: Studio module is bottleneck (2-5 min per 30s video)

  dependencies:
    python: ">=3.9"
    system:
      required:
        - ffmpeg (audio conversion)
      recommended:
        - libsndfile (audio I/O)
        - Blender 3.6+ (video generation)
      optional:
        - CUDA 11.8+ (GPU acceleration)

# ============================================================================
# RECOMMENDED NEXT STEPS
# ============================================================================

recommendations:

  immediate_priority:
    - task: Complete Blender asset acquisition
      reason: Unblocks video generation feature (only 7 assets remaining)
      effort: Low (2-4 hours)
      impact: High (enables full video pipeline)
      steps:
        - Download 5-6 animations from Mixamo (free)
        - Import FBX files into Blender
        - Save as .blend files in studio/assets/actions/
        - Find/create DJ booth environment (studio_default.blend)
        - Run validation to confirm all assets present

  short_term:
    - task: Test end-to-end video pipeline
      prerequisite: Blender assets complete
      steps:
        - Run run_batch.py with test audio
        - Verify all platform variants generate correctly
        - Test Blender rendering performance
        - Enable Generate Video tab in UI

    - task: Create sample library
      reason: Demonstrate system capabilities
      steps:
        - Ingest 10-20 diverse songs
        - Run batch analysis
        - Test all 8 mashup types
        - Document best practices

  medium_term:
    - task: Optimize video rendering performance
      ideas:
        - Parallel platform encoding
        - Lower quality preview mode
        - Render caching

    - task: Improve UI/UX
      ideas:
        - Real-time mashup preview
        - Waveform visualization
        - Better error messages
        - Progress indicators for video generation

  long_term:
    - task: Build asset library
      ideas:
        - Multiple avatar characters
        - Wardrobe/props system
        - Additional studio environments
        - Community asset sharing

    - task: Cloud deployment
      ideas:
        - Web-accessible UI
        - User accounts and libraries
        - Rendering queue system
        - API for integrations

# ============================================================================
# DEVELOPMENT WORKFLOW
# ============================================================================

dev_workflow:

  setup:
    - Clone repository
    - Create virtual environment (python -m venv venv)
    - Install dependencies (pip install -r requirements.txt)
    - Configure API keys (.env file)
    - Check dependencies (scripts/check_dependencies.sh)

  running:
    web_ui: streamlit run mixer_ui.py
    cli: python -m mixer --help

  testing:
    all_tests: pytest tests/ -v
    with_coverage: pytest tests/ -v --cov=mixer --cov-report=html
    single_module: pytest tests/unit/test_memory.py -v

  code_quality:
    format: black mixer/ tests/
    type_check: mypy mixer/

  benchmarking:
    audio_workflow: python scripts/benchmark.py
    video_pipeline: python scripts/benchmark_pipeline.py --audio test.wav --iterations 3

# ============================================================================
# DOCUMENTATION RESOURCES
# ============================================================================

documentation:
  user_facing:
    - README.md (project overview, quick start)
    - SETUP.md (comprehensive new machine setup)
    - UI_GUIDE.md (Streamlit web interface guide)

  developer:
    - CLAUDE.md (AI assistant developer guide)
    - PRD.md (product requirements - 1360 lines)
    - CONTINUITY.md (architecture, decisions, state tracking)

  specialized:
    - docs/crossfade-club/CROSSFADE_CLUB_PRD.md (video system PRD - 35 sections)
    - docs/crossfade-club/CROSSFADE_CLUB_COMPLETE.md (implementation summary)
    - director/README.md (Director Agent documentation)
    - studio/assets/README.md (Blender asset specifications)
    - batch/README.md (batch pipeline documentation)

  research:
    - docs/research/blender-assets/synthesis.md (asset research synthesis)
    - Multiple LLM responses (OpenAI, Claude, Gemini, Perplexity)

  handoffs:
    location: thoughts/shared/handoffs/general/
    count: 15 session handoffs
    latest: 2026-01-27_avatar-import-complete.yaml
    format: YAML with sections (goal, done, blockers, decisions, findings, next)

# ============================================================================
# PROJECT MATURITY ASSESSMENT
# ============================================================================

maturity:

  audio_pipeline:
    status: production_ready
    completeness: 100%
    stability: high
    testing: comprehensive (170+ tests)
    documentation: excellent
    ready_for: production use, real-world testing, user feedback

  video_pipeline:
    status: code_complete_awaiting_assets
    completeness: 88% (7/8 assets missing)
    stability: high (code tested, ready to use)
    testing: comprehensive (67 tests)
    documentation: excellent
    ready_for: asset acquisition, then production testing

  overall_project:
    phase: Late development / Early production
    strengths:
      - Comprehensive testing
      - Excellent documentation
      - Clean architecture
      - Multiple interfaces (CLI, UI)
      - Real-world use cases validated

    weaknesses:
      - Video pipeline blocked on assets
      - Large dependency footprint (~5GB)
      - No cloud deployment option
      - Limited error recovery in workflow

    recommendation: |
      Project is in excellent shape. Audio pipeline is production-ready and can be used immediately.
      Video pipeline needs 2-4 hours of asset work to become fully functional.

      Best next action: Complete Blender asset acquisition to unlock video generation,
      then test end-to-end pipeline with real-world audio to validate performance
      and identify any edge cases.

# ============================================================================
# QUICK START GUIDE
# ============================================================================

quick_start:

  for_audio_mashups:
    prerequisites:
      - Python 3.9+
      - ffmpeg installed
      - API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY)

    steps:
      - cd /home/craig/AI_Workspace/synterra/AI_Mixer
      - python -m venv venv && source venv/bin/activate
      - pip install -r requirements.txt
      - cp .env.template .env  # Add API keys
      - streamlit run mixer_ui.py
      - Upload songs, create mashups via UI

    cli_alternative:
      - python -m mixer auto path/to/song.mp3
      - python -m mixer interactive  # Guided mode

  for_video_generation:
    prerequisites:
      - All audio prerequisites
      - Blender 3.6+ installed
      - 8 Blender assets in studio/assets/

    current_status: BLOCKED - 7 assets missing

    when_ready:
      - Enable Generate Video tab in mixer_ui.py
      - Upload audio mashup
      - Select theme and platforms
      - Generate videos

    cli_alternative:
      - python run_batch.py --audio mashups/test.wav --song-id test

# ============================================================================
# CONTACT & SUPPORT
# ============================================================================

support:
  documentation: See README.md, CLAUDE.md, UI_GUIDE.md
  testing: pytest tests/ -v
  debugging: Check mixer.log for detailed logs
  benchmark: python scripts/benchmark.py

# ============================================================================
# SESSION METADATA
# ============================================================================

session_metadata:
  analyzed_by: Claude Sonnet 4.5 (onboarding agent)
  analysis_date: 2026-02-16
  codebase_snapshot: Latest (post Session 13)
  total_files_analyzed: 50+
  total_documentation_read: 8 files
  handoff_documents_reviewed: 15

  key_findings:
    - Audio pipeline is production-ready and well-tested
    - Video pipeline is code-complete but blocked on assets (1/8 complete)
    - 237+ tests passing with high coverage
    - Excellent documentation across all phases
    - Clean architecture with clear separation of concerns
    - Recent progress on asset acquisition (avatar imported in Session 13)

  confidence_level: high
  recommended_focus: Complete Blender asset acquisition to unlock video pipeline
